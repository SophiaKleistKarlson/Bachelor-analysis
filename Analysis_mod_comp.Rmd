---
title: "Analysis pipelines"
author: "Sophia Kleist Karlson"
date: "13 nov 2020"
output: html_document
---

```{r}
# set working directory
setwd("~/Social Transmission Study/Analysis of drawings/")

# load necesary packages through pacman
pacman::p_load(tidyverse, brms, ggplot2, stringr, dplyr)

# RStudio version
RStudio.Version()

# read data and delete the first unnecessary columns
data_comp <- read_csv("data/csv_files/all_data_w_source.csv") # we use all_data_w_all_conv_source.csv
data_comp$X1 <- NULL
```


Preparing the data and checking stuff
```{r}
# Checking classes

# Generation, complexity and confidence should be numeric
class(data_comp$Generation)
class(data_comp$Confidence)
class(data_comp$Complexity)

# Subject and Drawing ID should be character
class(data_comp$Subject)
class(data_comp$Drawing_ID)

# Chain, condition and Source_image should be factors
class(data_comp$Chain)
class(data_comp$Condition)
class(data_comp$Source_image)

data_comp$Chain <- as.factor(data_comp$Chain)
data_comp$Condition <- as.factor(data_comp$Condition)
data_comp$Source_image <- as.factor(data_comp$Source_image)


# Chose the variables needed for the model
df_complexity <- data_comp %>% select(Subject, Chain, Generation, Condition, Source_image, Complexity)#, Drawing_ID

```


Modeling
```{r}
# Set seed so that the analysis can be re-run and give the same results
set.seed(555)

# scaling complexity to make it easier to deal with and interpret
df_complexity$Complexity <- scale(df_complexity$Complexity)

# Define the model
complexity_mod <- bf(Complexity ~ 0 + Condition + mo(Generation) + Condition:mo(Generation) + 
                       (1 + Condition | gr(Subject, by = Chain)) +
                       (1 + Condition + mo(Generation) + Condition:mo(Generation) | Source_image))


# Figure out what priors we'll need
get_prior(complexity_mod, family = gaussian, df_complexity)

# Checking range, mean and standard deviation of complexity, to determine which family to choose and to use for beta- and intercept-priors
range(df_complexity$Complexity)
mean(df_complexity$Complexity)
sd(df_complexity$Complexity)

# For choosing the sd prior - GROUP BY DRAWING AND NOT SUBJECT???
df_part <- df_complexity %>% group_by(Subject) %>% summarize(compl_mean = mean(Complexity)) #find mean complexity for each participant
sd(df_part$compl_mean) #get the standard deviation of the mean complexity for each participant = 3159.295. Divide this in two = 1579.648.


prior_complexity_mod <- c(
  prior(normal(0, 1),           class = b), #mean and sd of complexity: 24641.25, 6401.52. z-scored: 0, 1
  prior(normal(1, 0.5),         class = sigma), #mean: sd of complexity sigma: half of the sd of complexity: 6401.52, 3200.76. z-scored: 1, 0.5
  prior(lkj(1),                 class = cor),# I choose lkj prior of 1 - WHY??
  
  # simo priors for the monotonic generation variable: mean is 1 for a uniform prior, sigma is K-1, where K is the number of levels in the monotonic variable (we have 8 generations)
  prior(dirichlet(rep(1, 7)),   class = simo, coef = moGeneration:Condition21),                 
  prior(dirichlet(rep(1, 7)),   class = simo, coef = moGeneration:Condition31),             
  prior(dirichlet(rep(1, 7)),   class = simo, coef = moGeneration:Condition41),            
  prior(dirichlet(rep(1, 7)),   class = simo, coef = moGeneration1),
  
  prior(normal(0, 0.25),        class = sd) #mean: 0 (I expect that they might not vary at all). sd for the mean complexity for each participant = 2780.45. sigma should go from 0 (the mean of the prior) to around that -> sigma: 1579.648. Z-scored: 0, 0.25.
)


# Running the model to check priors
complexity_mod0 <- brm(
  formula = complexity_mod, 
  prior = prior_complexity_mod,
  data = df_complexity,
  chains = 2,
  cores = 2,
  sample_prior = "only"
)


# Prior predictive check
pp_check(complexity_mod0, nsamples = 100) 


# The actual model:
complexity_mod1 <- brm(
  formula = complexity_mod, 
  prior = prior_complexity_mod,
  data = df_complexity,
  chains = 2,
  cores = 2,
  sample_prior = T,
  iter = 4000,
  control = list(adapt_delta=0.99, max_treedepth=20)
)

# Posterior predictive check
pp_check(complexity_mod1, nsamples = 100)



# Model summary
summary(complexity_mod1) # Warnings? Suspicious Rhat activity? Bad priors?

# Plot the model to get trace plots
plot(complexity_mod1)


# Rank trace plots
mcmc_rank_overlay(complexity_mod1, 
                  pars = c("b_Intercept", "b_Condition2", "b_Condition3", "b_Condition4")) + 
  theme_classic()

mcmc_rank_overlay(complexity_mod1, 
                  pars = c("b_Generation", "b_Condition2:Generation", "b_Condition3:Generation", "b_Condition4:Generation")) + 
  theme_classic()

mcmc_rank_overlay(complexity_mod1, 
                  pars = c("sigma")) + 
  theme_classic()


complexity_mod1

# After trying different hypotheses, these turned out to be the ones with highest posterior probability
hypothesis(complexity_mod1,"Condition1 > Condition2") 
hypothesis(complexity_mod1,"Condition1 > Condition3")
hypothesis(complexity_mod1,"Condition1 > Condition4")

hypothesis(complexity_mod1,"Condition2 = Condition3") 
hypothesis(complexity_mod1,"Condition3 = Condition4")
hypothesis(complexity_mod1,"Condition2 = Condition4")

# these don't work...
hypothesis(complexity_mod1,"Generation < 0")
hypothesis(complexity_mod1,"Condition2:moGeneration < 0")
hypothesis(complexity_mod1,"Condition3:Generation < 0")
hypothesis(complexity_mod1,"Condition4:Generation < 0")



plot(hypothesis(complexity_mod1, "Condition1 > Condition2")) 
plot(hypothesis(complexity_mod1, "Condition1 > Condition3")) 
plot(hypothesis(complexity_mod1, "Condition1 > Condition4")) 

plot(hypothesis(complexity_mod1,"Condition2 = Condition3"))
plot(hypothesis(complexity_mod1,"Condition3 = Condition4"))
plot(hypothesis(complexity_mod1,"Condition2 = Condition4"))


plot(hypothesis(complexity_mod1, "moGeneration > 0")) 



# Plot conditional effects
conditional_effects(complexity_mod1)
```


